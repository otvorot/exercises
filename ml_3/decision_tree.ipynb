{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните мы познакомимся с ещё одним семейством моделей машинного обучения — деревьями решений. Для начала поговорим о том, что такое дерево решений и как с его помощью решают задачу классификации.\n",
    "\n",
    "Деревья решений являются одним из наиболее понятных человеку и в то же время мощных алгоритмов принятия решений. К тому же на их основе строятся самые эффективные ансамблевые модели машинного обучения, такие как случайный лес, о котором мы поговорим далее.\n",
    "\n",
    "Алгоритмы на основе деревьев решений могут использоваться как для решения задач классификации, так и для регрессии. В этом модуле мы разберём задачу классификации, а в дальнейшем, когда будем разбирать математическую составляющую алгоритмов, поговорим о том, как научить дерево решать задачу регрессии.\n",
    "\n",
    "Если коротко, решающее дерево предсказывает значение целевой переменной с помощью применения последовательности простых решающих правил. Этот процесс в некотором смысле согласуется с естественным для человека процессом принятия решений.\n",
    "\n",
    "ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ДЕРЕВЕ РЕШЕНИЙ\n",
    "\n",
    "Начнём сразу с примера.\n",
    "\n",
    "Представьте, что у вас есть автомобиль, который вы решили застраховать. Вы приходите в страховую компанию, где вам дают заполнить анкету. По этой анкете сотрудник страховой компании будет принимать решение, стоит ли выдавать вам страховку.\n",
    "\n",
    "Сотрудник в свою очередь будет руководствоваться примерно следующим регламентом:\n",
    "\n",
    "Если возраст владельца > 40 лет, то:\n",
    "Если место эксплуатации автомобиля — город, то:\n",
    "Если стаж > 10 лет, то:\n",
    "Застраховать.\n",
    "Если стаж < 10 лет, то:\n",
    "Не страховать.\n",
    "Если место эксплуатации автомобиля — сельская местность, то:\n",
    "Застраховать.\n",
    "Если возраст владельца ≤ 40 лет, то:\n",
    "Если аварий не было зафиксировано, то:\n",
    "Застраховать.\n",
    "Если были аварии, то:\n",
    "Если тип автомобиля — минивэн, то:\n",
    "Застраховать.\n",
    "Если тип автомобиля — спорткар, то:\n",
    "Не страховать.\n",
    "То есть сотрудник при принятии решения использует информацию, предоставленную вами в анкете, и подает её на вход вложенного условного оператора.\n",
    "\n",
    "Для простоты восприятия можно представить такой подход визуально в виде следующего дерева:\n",
    "\n",
    "img\n",
    "\n",
    "Аналогичным образом работает и алгоритм машинного обучения под названием «дерево решений» (Decision Tree). \n",
    "\n",
    "Если дерево уже обучено, то есть уже сформулированы условия в прямоугольниках, то, когда в страховую компанию придёт новый автовладелец, сотруднику будет достаточно прогнать данные клиента через дерево решений и таким образом принять решение, то есть произвести классификацию.\n",
    "\n",
    "Вот ещё один пример дерева решений. Большинство из нас когда-нибудь играли в игру «Слова на лбу» или «Тарантинки». На лоб каждого из игроков приклеивается бумажка с написанным на ней словом. Игрок может задавать другим игрокам вопросы о загаданном ему предмете/животном/человеке и т. д. Другие игроки могут отвечать на вопросы только «Да» и «Нет». Цель — за минимальное количество вопросов догадаться, о чём идёт речь.\n",
    "\n",
    "Логика «если …, то …» используется людьми повседневно и поэтому интуитивно понятна каждому из нас. На основании этих рассуждений можно построить мощный алгоритм машинного обучения.\n",
    "\n",
    "Деревья решений находят своё применение во множестве прикладных задач.\n",
    "\n",
    "Успешнее всего деревья применяют в следующих областях:\n",
    "\n",
    "Банковское дело. Оценка кредитоспособности клиентов банка при выдаче кредитов.\n",
    "Промышленность. Контроль качества продукции (обнаружение дефектов в готовых товарах), испытания без нарушений (например, проверка качества сварки) и т. п.\n",
    "Медицина. Диагностика заболеваний разной сложности.\n",
    "Молекулярная биология. Анализ строения аминокислот.\n",
    "Торговля. Классификация клиентов и товара.\n",
    " \n",
    "\n",
    "Теперь перейдём к формальной части. Нам важно уже сейчас познакомиться с терминологией деревьев решений, чтобы понять общий принцип их обучения.\n",
    "\n",
    "Пусть у нас есть всё та же матрица наблюдений X, в которой содержатся наблюдения и характеризующие их признаки (привычный нам DataFrame), и правильные ответы y — метки классов. \n",
    "\n",
    "Дадим определение дереву решений и его составляющим ↓\n",
    "\n",
    "Формально структура дерева решений — это связный ациклический граф. Что это значит?\n",
    "\n",
    "Граф — это абстрактная топологическая модель, которая состоит из вершин и соединяющих их рёбер.\n",
    "\n",
    "Связный граф — это граф, в котором между любой парой существует направленная связь.\n",
    "\n",
    "Ациклический граф — это граф, в котором отсутствуют циклы, то есть в графе не существует такого пути, по которому можно вернуться в начальную вершину.\n",
    "\n",
    "img\n",
    "\n",
    "Примечание. Рекомендуем вам запомнить данное лаконичное определение дерева — так вы сможете показать свой уровень знаний перед будущим работодателем.\n",
    "\n",
    "В дереве решений можно выделить три типа вершин:\n",
    "\n",
    "img\n",
    "\n",
    "Корневая вершина (root node) — то, откуда всё начинается. Это первый и самый главный вопрос, который дерево задаёт объекту. В примере со страхованием это был вопрос «Возраст автовладельца > 40».\n",
    "Внутренние вершины (intermediate nodes) — это дополнительные уточняющие вопросы, которые дерево задаёт объекту. \n",
    "Листья (leafs) — конечные вершины дерева. Это вершины, в которых содержится конечный «ответ» — класс объекта.\n",
    "Максимально возможная длина от корня до самых дальних листьев (не включая корневую) называется максимальной глубиной дерева (max depth).\n",
    "\n",
    "Во внутренней или корневой вершине признак проверяется на некий логический критерий, по результатам которого мы движемся всё глубже по дереву. Например, «Количество кредитов  1». \n",
    "\n",
    "Логический критерий, который находится в каждой вершине, называется предикатом, или решающим правилом.\n",
    "\n",
    "На самом деле все предикаты — это просто взятие порога по значению какого-то признака. Формально это записывается следующим образом:\n",
    "\n",
    "Предикат вершины дерева   (где   — это номер вершины) равен 1 («Да»), если признак  меньше либо равен значению , и 0 («Нет») — в противном случае. Функция  с квадратными скобками — это уже знакомая нам индикаторная функция: она равна 1, если условие внутри скобок выполняется, и 0 — в противном случае.\n",
    "\n",
    "Примечание. В зависимости от реализации предикат может быть с условием  или . В реализации sklearn используется условие . Но вы можете встретить другую формулировку предикатов в иных реализациях или в литературе.\n",
    "\n",
    "Если результат предиката равен 1, то мы переходим по левой ветви дерева к следующему узлу, в противном случае — по правой ветви дерева к следующему узлу.\n",
    "\n",
    "А что насчёт геометрии?\n",
    "\n",
    "Каждый новый вопрос дерева решений при его обучении разбивает пространство признаков на две части: в первую часть отправляются наблюдения, для которых предикат истинен, а во вторую — для которых он ложен.\n",
    "\n",
    "Посмотрим, как это будет выглядеть, на примере. \n",
    "\n",
    "Вам уже знакома задача классификации про ирисы. Ирисы Фишера — это задача, на которой Рональд Фишер ещё в 1936 году (почти 100 лет назад!) продемонстрировал работу алгоритма, разделяющего ирисы на сорта в зависимости от параметров долей околоцветника.\n",
    "\n",
    "Пусть у нас есть следующие признаки:\n",
    "\n",
    "длина внутренней доли околоцветника (англ. petal length);\n",
    "ширина внутренней доли околоцветника (англ. petal width).\n",
    "На основании этих двух признаков требуется разделить ирисы на три сорта:\n",
    "\n",
    "ирис щетинистый (Iris Setosa);\n",
    "ирис виргинский (Iris virginica);\n",
    "ирис разноцветный (Iris versicolor).\n",
    "Пусть мы обучили на этих данных дерево решений с максимальной глубиной 2. Оно получилось вот таким:\n",
    "\n",
    "img\n",
    "\n",
    "В каждом блоке указаны следующие данные:\n",
    "\n",
    "Предикат  — условие, по которому выборка делится на две части: на ту, для которой условие выполняется, и ту, для которой не выполняется.\n",
    "gini — критерий информативности Джини, о котором мы поговорим чуть позже.\n",
    "samples — количество объектов, которые мы проверяем на данном шаге.\n",
    "value — распределение по классам для объектов, которые мы проверяем на данном шаге: например value=[0, 50, 50] означает, что на текущем этапе разделения в выборке находится 0 объектов класса setosa и по 50 объектов классов versicolor и virginica.\n",
    "class — класс, который мы присваиваем, если завершим выполнение алгоритма на данном шаге.\n",
    "А вот так будет выглядеть наш процесс разделения цветов на классы:\n",
    "\n",
    "img\n",
    "\n",
    "Как происходит построение разделяющих плоскостей?\n",
    "\n",
    "Глубина дерева = 0.\n",
    "\n",
    "Дерево задаёт первый вопрос: . Это выражение соответствует вертикальной прямой, которая делит пространство на две части по признаку petal length.\n",
    "\n",
    "В левую часть пространства попали 50 наблюдений. Это только жёлтые точки пространства — цветы setosa. Значит, дальнейшее разделение не имеет смысла.\n",
    "\n",
    "В правую часть пространства попали 100 наблюдений. Это и синие, и зелёные объекты классов versicolor и virginica. Значит, нужно попробовать задать ещё одно решающее правило.\n",
    "\n",
    "Глубина дерева = 1.\n",
    "\n",
    "Дерево задаёт второй вопрос: . Это выражение соответствует горизонтальной прямой, которая делит оставшееся после прошлого разделения пространство на две части по признаку petal width.\n",
    "\n",
    "В нижнюю (синюю) часть этого пространства попали 54 наблюдения. Из них 49 цветов класса versicolor и 5 цветов класса virginica.\n",
    "\n",
    "Максимальная глубина достигнута. В полученной части пространства преобладает класс versicolor, значит все наблюдения, которые находятся в этой части, дерево будет относить к классу versicolor.\n",
    "\n",
    "В верхнюю (зелёную) часть этого пространства попали 46 наблюдений. Из них 1 цветок класса versicolor и 45 цветов класса virginica.\n",
    "\n",
    "Максимальная глубина достигнута. В полученной части пространства преобладает класс virginica, значит все наблюдения, которые находятся в этой части, дерево будет относить к классу virginica.\n",
    "\n",
    "Отметим, что деление пространства можно продолжать до тех пор, пока пространство не будет разделено так, чтобы верно выделить каждый из классов. \n",
    "\n",
    "Кстати, для каждой области можно подсчитать вероятность каждого из классов. Это просто отношение количества объектов -класса, которые попали в лист дерева, к общему количеству объектов в листе.\n",
    "\n",
    "Например, для синей области вероятности будут равны:\n",
    "\n",
    "к\n",
    "л\n",
    "а\n",
    "с\n",
    "с\n",
    "к\n",
    "л\n",
    "а\n",
    "с\n",
    "с\n",
    "к\n",
    "л\n",
    "а\n",
    "с\n",
    "с\n",
    "Теперь, когда мы разобрались с терминологией и геометрией, давайте поговорим о том, как строится решающее дерево.\n",
    "\n",
    "Задание 6.1\n",
    "1/1 point (graded)\n",
    "Что представляет собой структура дерева решений?\n",
    "Циклический граф\n",
    "Уравнение плоскости\n",
    "Ациклический связный граф\n",
    "Уравнение параболы\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 6.2\n",
    "1/1 point (graded)\n",
    "Как называется записанное в вершине дерева условие, которое делит выборку, пришедшую в вершину, на две части?\n",
    "Предиктор\n",
    "Предикат\n",
    "Ребро\n",
    "Глубина дерева\n",
    "верно\n",
    "Ответ\n",
    "Верно:Условие, записанное в вершине дерева, называется предикатом и записывается следующим образом: .\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 6.3\n",
    "1/1 point (graded)\n",
    "\n",
    "На схеме ниже представлено обученное дерево решений. К какому сорту относится цветок, если его параметры: petal length = 3, petal width = 1, sepal length = 5, sepal width = 2?\n",
    "\n",
    "img\n",
    "\n",
    "Ирис щетинистый (Iris Setosa)\n",
    "Ирис виргинский (Iris virginica)\n",
    "Ирис разноцветный (Iris versicolor)\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 6.4\n",
    "1/1 point (graded)\n",
    "Чему равна максимальная глубина дерева из предыдущего задания?\n",
    "3\n",
    "5\n",
    "6\n",
    "4\n",
    "верно\n",
    "Ответ\n",
    "Верно:Максимальная глубина — это количество уровней в дереве от корневой вершины до самых листьев, не включая корень. Посчитав количество уровней в дереве, мы увидим, что максимальная глубина равна 5.\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "ПРОЦЕСС ПОСТРОЕНИЯ ДЕРЕВА РЕШЕНИЙ\n",
    "\n",
    "✍ Существует множество стратегий построения деревьев решений. Мы рассмотрим стратегию, реализованную в библиотеке sklearn, — алгоритм CART (Classification and Regression Tree), который предназначен для построения бинарных деревьев решений (деревьев, у которых каждая вершина связана с двумя другими вершинами нижнего уровня). Данный алгоритм, как следует из его названия, предназначен для решения задач классификации и регрессии.\n",
    "\n",
    "Внимательный студент уже заметил, что построение дерева решений можно описать рекурсией. Каждая вершина дерева порождает две других вершины, а они в свою очередь порождают новые вершины, и так происходит до тех пор, пока не выполнится некоторый критерий остановки, например в вершине не останутся только наблюдения определённого класса.\n",
    "\n",
    "Примечание. Если вы забыли, что такое рекурсия, рекомендуем вам вернуться к модулю по продвинутому использованию функций и активировать рекурсивное мышление, оно нам понадобится.\n",
    "\n",
    "Пусть у нас есть матрица наблюдений X и столбец с ответами — метками классов y. На основе примеров и ответов мы хотим построить дерево решений, которое будет производить классификацию.\n",
    "\n",
    "Итак, псевдокод рекурсивной функции для построения решающего дерева будет выглядеть следующим образом (запускать код не нужно, так как он является абстрактным):\n",
    "\n",
    "def build_decision_tree(X, y):\n",
    "    node = Node()\n",
    "    if stopping_criterion(X, y) is True:\n",
    "        node = create_leaf_with_prediction(y)\n",
    "\treturn node\n",
    "    else:\n",
    "        X_left, y_left, X_right, y_right = best_split(X, y)\n",
    "        node.left = build_decision_tree(X_left, y_left)\n",
    "        node.right = build_decision_tree(X_right, y_right)\n",
    "Разберёмся, как работает алгоритм:\n",
    "\n",
    "1\n",
    "Создать новую вершину node.\n",
    "\n",
    "На первой итерации это будет корневая вершина. На последующих это будут внутренние вершины.\n",
    "\n",
    "2\n",
    "Проверить некоторый критерий остановки stop_criterion().\n",
    "\n",
    "Например, критерием остановки может быть следующее условие: все объекты, которые попали в вершину, — это объекты одного и того же класса.\n",
    "\n",
    "Или достигнута максимальная глубина дерева (max_depth), например 5. Это значит, что дерево не будет продолжать делиться, если глубина уже равна 5.\n",
    "\n",
    "Другой критерий: число наблюдений в листе (в sklearn этот параметр обозначен как min_samples_leaf) меньше заданного, например 7. Это значит, что при выполнении такого условия дерево продолжит делиться в том случае, если решающее правило выполняется как минимум для 7 наблюдений.\n",
    "\n",
    "2.1. Если условие остановки выполняется:\n",
    "\n",
    "Проверить, какой класс преобладает в текущей вершине. Превратить текущую вершину дерева в лист, где всем наблюдениям, которые попали в эту вершину, присвоить метку преобладающего класса.\n",
    "\n",
    "Прекратить построение дерева, вернув из алгоритма полученный лист.\n",
    "\n",
    "2.2. Если условие остановки не выполняется:\n",
    "\n",
    "Среди всех возможных предикатов  найти такой, который обеспечивает разбиение выборки наилучшим образом.\n",
    "\n",
    "То есть нужно найти такой признак  и пороговое значение , при которых достигается максимум некоторой информативности (существуют разные меры информативности, о них поговорим ниже). Назовём эту часть алгоритма некоторой абстрактной функцией best_split().\n",
    "\n",
    "Например, в нашем примере с ирисами это был предикат . Он обеспечил наилучшее разделение пространства на две части.\n",
    "\n",
    "В результате разбиения будут созданы два набора данных:\n",
    "\n",
    "X_left, y_left (левый), для которого выполняется условие ;\n",
    "X_right, y_right (правый), для которого условие не выполняется.\n",
    "Создаются две новые вершины: левая и правая, в каждую из которых отправляется соответствующий набор данных.\n",
    "\n",
    "То есть происходит рекурсивный вызов функции build_decision_tree(), и для каждой новой вершины алгоритм повторяется вновь с новым набором данных.\n",
    "\n",
    "Примечание. Вершина дерева node задаёт целое поддерево идущих за ним вершин, если такие имеются, а не только саму вершину.\n",
    "\n",
    "Центральный момент в построении дерева решений по обучающему набору данных — найти такой предикат , который обеспечит наилучшее разбиение выборки на классы. \n",
    "\n",
    "Как дерево определяет, какой вопрос нужно задать в каждой из вершин? \n",
    "\n",
    "Например, в задаче кредитного скоринга мы можем задавать множество различных вопросов в разной последовательности. Предикаты  в первой вершине могут быть различными:\n",
    "\n",
    "возраст заёмщика  25 лет,\n",
    "возраст заёмщика  40 лет,\n",
    "размер кредита  1000 $,\n",
    "наличие детей  0.5 (если наличие детей — бинарный категориальный признак: 1 — есть дети, 0 — нет детей),\n",
    "и так далее.\n",
    "Видно, что на место  и  можно подставить любой признак и порог соответственно.\n",
    "\n",
    "Признак  и его пороговое значение  в каждой из вершин и есть внутренние параметры дерева решений, которые мы пытаемся отыскать. Это аналог коэффициентов уравнения линейной и логистической регрессий. \n",
    "\n",
    "Какие же и в какой последовательности нужно задавать вопросы, или как подобрать оптимальные параметры дерева?\n",
    "\n",
    "Задание 6.5\n",
    "1/1 point (graded)\n",
    "Что происходит с вершиной, для которой выполняется условие остановки?\n",
    "Она удаляется из дерева, и алгоритм деления завершается.\n",
    "Происходит поиск такого предиката, который наилучшим образом по заданному критерию разделит набор данных на два, после чего вершина порождает две новые вершины.\n",
    "Она превращается в лист, и алгоритм её деления завершается.\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.Верно (1/1 балл)Review\n",
    "Задание 6.6\n",
    "1/1 point (graded)\n",
    "Что происходит с вершиной, для которой не выполняется условие остановки?\n",
    "Она удаляется из дерева, и алгоритм деления завершается.\n",
    "Происходит поиск такого предиката, который наилучшим образом по заданному критерию разделит набор данных на два, после чего вершина порождает две новые вершины.\n",
    "Она превращается в лист, и алгоритм её деления завершается.\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.Верно (1/1 балл)Review\n",
    "ПОИСК ПАРАМЕТРОВ ДЕРЕВА РЕШЕНИЙ\n",
    "\n",
    "→ Обратите внимание, что внутренние параметры дерева решений кардинально отличаются от линейных моделей.\n",
    "\n",
    "В линейных моделях мы пытались найти такие коэффициенты в уравнениях, при которых наблюдался минимум функции потерь.\n",
    "\n",
    "В деревьях же мы пытаемся выбрать такие признаки  и их пороговые значения , при которых произойдёт разделение набора на две части по какому-то критерию наилучшим образом. В нашем псевдокоде этот процесс организован в виде функции best_split().\n",
    "\n",
    "→ Важно понимать, что дерево решений — это топологический алгоритм, а не аналитический, то есть структуру дерева не получится описать в виде формулы, как те же линейные модели. Поэтому про стандартные методы оптимизации, такие как градиентный спуск или тем более метод наименьших квадратов, можно забыть. \n",
    "\n",
    "Чтобы интуитивно понять, как организуется поиск параметров, вспомним про игру «Слова на лбу».\n",
    "\n",
    "Пусть один человек загадывает знаменитость, а второй пытается отгадать, задавая только вопросы, на которые можно ответить «Да» или «Нет» (опустим варианты «не знаю» и «не могу сказать»).\n",
    "\n",
    "Какой вопрос отгадывающий задаст первым делом? Конечно, такой, который лучше всего уменьшит количество оставшихся вариантов.\n",
    "\n",
    "К примеру, вопрос «Это Анджелина Джоли?» в случае отрицательного ответа оставит более 7.5 миллиардов вариантов для дальнейшего перебора (строго говоря, поменьше, ведь не каждый человек — знаменитость, но всё равно немало), а вот вопрос «Это женщина?» отсечёт уже около половины знаменитостей.\n",
    "\n",
    "То есть, признак пол намного лучше разделяет выборку людей, чем признак это Анджелина Джоли, национальность — испанец или любит футбол.\n",
    "\n",
    "Интуитивно это соответствует уменьшению некоторой неопределённости, или, иначе говоря, повышению прироста информативности.\n",
    "\n",
    "В случае «угадайки» знаменитостей критериев отбора может быть бесчисленное количество. Но когда мы работаем с набором данных, у нас ограниченное количество признаков и для них есть ограниченное количество порогов. Тогда мы можем полным перебором найти такую комбинацию  и , которая обеспечит наилучшее уменьшение неопределённости.\n",
    "\n",
    "Неопределённость можно измерять различными способами, в деревьях решений для этого используются энтропия Шеннона и критерий Джини. Мы подробно обсудим их реализацию в модулях по математике.\n",
    "\n",
    "ОСТОРОЖНО, МАТЕМАТИКА!\n",
    "Пусть в вершину  попало множество  и  объектов из обучающей выборки размером , где  — количество наблюдений, а  — номер вершины.\n",
    "\n",
    "Параметры в условии  будут выбраны так, чтобы минимизировать некоторую функцию ошибки , зависящую от этих параметров:\n",
    "\n",
    "где  — номер признака, а  — пороговое значение.\n",
    "\n",
    "Параметры  и  мы выбираем простым перебором всех возможных значений. Действительно, признаков — конечное число, а из всех возможных значений порога  можно рассматривать только те, при которых получаются различные разбиения. \n",
    "\n",
    "После того как параметры были выбраны, множества  объектов из обучающей выборки и ответов к ним  разбиваются на два:  и , для которых условие  выполняется и не выполняется соответственно.\n",
    "\n",
    "Каждая из полученных выборок будет иметь свои размеры, назовём их  и . Тогда функция ошибки, численно выражающая неопределённость, будет состоять из двух слагаемых (неопределённость для левой и правой вершин) и определяться следующим образом:\n",
    "\n",
    "где  — это функция, которая называется критерием информативности. Её значение уменьшается с уменьшением разброса ответов на выборке.\n",
    "\n",
    "Критерии информативности:\n",
    "\n",
    "1\n",
    "Энтропия Шеннона:\n",
    "\n",
    "где  — количество классов,  — вероятность принадлежности объекта к -му классу,  — логарифм по основанию 2.\n",
    "\n",
    "Энтропия — это очень важное понятие, используемое в физике, теории информации и других областях. Опуская предпосылки введения этого понятия, отметим, что интуитивно энтропия соответствует степени хаоса в системе. Чем выше энтропия, тем менее упорядочена система, и наоборот.\n",
    "\n",
    "2\n",
    "Критерий Джини:\n",
    "\n",
    "где  — количество классов,  — вероятность принадлежности объекта к -му классу.\n",
    "\n",
    "Все слагаемые в сумме неотрицательные, поэтому критерий Джини также неотрицателен. Его минимум достигается только в том случае, когда все объекты в выборке относятся к одному классу.\n",
    "\n",
    "Давайте рассмотрим, как работают эти формулы, на примере.\n",
    "\n",
    "В качестве примера рассмотрим задачу сортировки шариков на две группы — жёлтого и синего цвета. В качестве критерия информативности возьмём энтропию. Этот пример поможет нам понять, как строится дерево решений с данным критерием.\n",
    "\n",
    "Итак, у нас есть всего один признак  — координата шарика (от 0 до 19), то есть . Классов у нас два — синие и жёлтые шарики, то есть .\n",
    "\n",
    "img\n",
    "\n",
    "На рисунке 9 синих шариков и 11 жёлтых. Всего в совокупности . Если мы наудачу вытащим шарик, то он с вероятностью  будет синим и с вероятностью  — жёлтым.\n",
    "\n",
    "Значит, энтропия начального состояния:\n",
    "\n",
    "Энтропия не равна 0, а значит нужно попробовать ввести условие (предикат) , чтобы разделить выборку на две части.\n",
    "\n",
    "Полным перебором выбираем значение порога  от 0 до 19. Для примера рассмотрим случай, когда . То есть мы рассматриваем предикат .\n",
    "\n",
    "Посмотрим, как изменится энтропия, если разбить шарики на две группы — с координатой меньше либо равной 12 и больше 12.\n",
    "\n",
    "img\n",
    "\n",
    "В левой группе оказалось  шаров, из которых 8 синих и 5 жёлтых. Энтропия этой группы равна:\n",
    "\n",
    "В правой группе оказалось  шаров, из которых 1 синий и 6 жёлтых. Энтропия правой группы равна:\n",
    "\n",
    "Получается, разделив шарики на две группы по признаку «координата меньше либо равна 12»: , мы уже получили более упорядоченную систему, чем вначале.\n",
    "\n",
    "Функция ошибки (суммарная неопределённость в вершине) при этом равна:\n",
    "\n",
    "Такие вычисления мы должны произвести для всех возможных значений , а если признаков не один, а несколько, то ещё и для всех признаков. После этого выбирается такая комбинация , при которых значение  наименьшее. Затем, выбрав предикат, мы можем перейти к построению следующей вершины.\n",
    "\n",
    "Продолжим деление шариков на группы до тех пор, пока в каждой группе шарики не будут одного цвета.\n",
    "\n",
    "img\n",
    "\n",
    "Для правой группы потребовалось всего одно дополнительное разбиение по признаку «координата меньше либо равна 18», для левой — ещё три. Очевидно, энтропия группы с шариками одного цвета равна 0, что соответствует представлению, что группа шариков одного цвета — упорядоченная.\n",
    "\n",
    "В итоге мы построили дерево решений, предсказывающее цвет шарика по его координате. Отметим, что такое дерево решений может плохо работать для новых объектов (определения цвета новых шариков), поскольку оно идеально подстроилось под обучающую выборку (изначальные 20 шариков). Для классификации новых шариков лучше подойдёт дерево с меньшим числом «вопросов» (или разделений), пусть даже оно и неидеально разбивает по цветам обучающую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДОСТОИНСТВА И НЕДОСТАТКИ ДЕРЕВЬЕВ РЕШЕНИЙ\n",
    "\n",
    "Обобщим всё вышесказанное, выделив основные достоинства и недостатки деревьев решений.\n",
    "\n",
    "Img\n",
    "\n",
    "Дерево решений не требует нормализации/стандартизации данных.\n",
    "Наличие пропусков не оказывает существенного влияния на построение дерева.\n",
    "За счёт своей простоты модель деревьев решений интуитивно понятна и легко объяснима даже людям, не разбирающимся в методе.\n",
    "Приятный побочный эффект построения дерева решений — получение значимости признаков. Однако коэффициенты значимости целиком и полностью зависят от сложности дерева.\n",
    "Img\n",
    "\n",
    "В силу дискретной топологической структуры дерево не дифференцируется по параметрам: стандартные алгоритмы поиска параметров, такие как градиентный спуск, не работают. Приходится использовать полный перебор.\n",
    "Примечание. Количество перебираемых вариантов можно сократить, используя методы динамического программирования (их изучение не входит в рамки нашего курса).\n",
    "\n",
    "Так как метод является жадным, он долго обучается из-за полного перебора. Требует затрат больших вычислительных мощностей (по сравнению с другими алгоритмами). Особенно это ощутимо при большом количестве признаков на глубоких деревьях.\n",
    "Очень сильная склонность к переобучению. Необходим подбор внешних параметров: max_depth, min_sample_leaf и другие (о том, как организовать этот подбор, мы поговорим в отдельном модуле).\n",
    "Небольшое изменение в данных может заметно повлиять на структуру дерева.\n",
    "При работе с непрерывными числовыми признаками дерево делит их на категории и теряет информацию. Лучше всего дерево работает, если перевести числовые признаки в категориальные."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
