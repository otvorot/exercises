{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка качества модели для каждой комбинации гиперпараметров является дорогостоящей частью оптимизации — на приведённых крохотных сетках по нескольким параметрам это занимает минуты, но в реальных масштабах это занимает часы и сутки. Поэтому в идеале мы хотим оптимизировать гиперпараметры самым эффективным образом. \n",
    "\n",
    "Один из способов  — это байесовская оптимизация. Она отличается от случайного поиска или поиска по сетке тем, что учитывает предыдущие результаты, а не выбирает комбинации из вариантов, не имеющих информации о прошлых оценках. Во многих случаях это позволяет найти лучшие значения гиперпараметров модели за меньшее количество времени. Таким образом, мы получаем и более быструю оптимизацию, и более качественный результат. Это два желаемых результата, особенно когда мы работаем с настройкой гиперпараметров моделей МО.\n",
    "\n",
    "Существует несколько разных алгоритмов для этого типа оптимизации, но особенно используемым является Tree-Structured Parzen Estimators (TPE).\n",
    "\n",
    "Tree-Structured Parzen Estimators (TPE)\n",
    "\n",
    "1На каждой итерации алгоритм TPE учитывает информацию о прошлых опробованных комбинациях гиперпараметров и только потом принимает решение, какой набор следует попробовать дальше. \n",
    "\n",
    "Чтобы приступить к использованию TPE, необходимо выполнить несколько итераций с помощью случайного поиска. \n",
    "\n",
    "2На следующем шаге происходит разделение собранных наборов на две группы:\n",
    "\n",
    "в первую группу входят наборы, дающие наилучшие результаты после оценки;\n",
    "во вторую — все остальные.\n",
    "На изображении ниже: первая группа — красные точки находятся в области минимума целевой функции; вторая группа — синие точки, все остальные.\n",
    "\n",
    "\n",
    "\n",
    "Источник\n",
    "\n",
    "Основная цель алгоритма — найти набор гиперпараметров, который с большей вероятностью будет в первой группе и с меньшей вероятностью во второй группе. Таким образом, для принятия следующего решения используется целое распределение наилучших комбинаций — красные точки на графике.\n",
    "\n",
    "3Далее TPE моделирует вероятности правдоподобия для каждой из групп, используя формулу Байеса:\n",
    "\n",
    "где  — гиперпараметры,  — соответствующая оценка качества модели.\n",
    "\n",
    "Подробнее про теорему Байеса можно прочитать по ссылке.\n",
    "\n",
    "4Затем, используя вероятность правдоподобия из первой группы, отбирается набор комбинаций, которые с большей вероятностью попадут в первую группу и с меньшей вероятностью — во вторую. \n",
    "\n",
    "где  — это вероятность гиперпараметров с учётом оценки целевой функции,  — вероятность быть в первой группе,  — вероятность быть во второй группе\n",
    "\n",
    "Определяем ожидаемое улучшение для каждой комбинации:\n",
    "\n",
    "где  — это знак математического ожидания.\n",
    "5Шаги 2-4  будет выполняться до тех пор, пока не будет достигнуто максимальное количество итераций. \n",
    "\n",
    "В итоге мы найдём наилучшую комбинацию гиперпараметров.\n",
    "\n",
    "Более подробное описание алгоритма с математическими выкладками вы можете найти здесь.\n",
    "\n",
    "Hyperopt\n",
    "\n",
    "Hyperopt — это библиотека Python с открытым исходным кодом на основе байесовской оптимизации, в которой реализован алгоритм Tree-Structured Parzen Estimators (TPE).\n",
    "\n",
    "Три шага для использования Hyperopt:\n",
    "\n",
    "1Задание пространства поиска гиперпараметров. \n",
    "\n",
    "Объявляем список гиперпараметров, тип распределения и его границы.\n",
    "\n",
    "Основные (наиболее часто используемые) типы:\n",
    "\n",
    "hp.choice(label, options) — равновероятный выбор из массива. Массив (список/кортеж) вы задаёте сами, в списке могут быть как числа, так и строки (категории), но, как правило, данный метод используется для оптимизации категориального гиперпараметра (например, тип регуляризации в линейной регрессии или критерий информативности в деревьях);\n",
    "hp.randint(label, upper) — возвращает случайное целое число из диапазона [0, upper];\n",
    "hp.uniform(label, low, high) — создаёт равномерное непрерывное распределение и возвращает случайное число (не обязательно целое) из диапазона [low, high];\n",
    "hp.normal(label, mu, sigma) — создаёт нормальное непрерывное распределение с параметрами mu и sigma и возвращает случайное число из этого распределения;\n",
    "hp.lognormal(label, mu, sigma) — создаёт логнормальное непрерывное распределение с параметрами mu и sigma и возвращает случайное число из этого распределения.\n",
    "2Задание целевой функции. \n",
    "\n",
    "Создаём модель МО, передаём ей данные и оцениваем её на основе выбранной метрики. Можем минимизировать/максимизировать значение метрики.\n",
    "\n",
    "3Задание алгоритма поиска:\n",
    "\n",
    "Random Search.\n",
    "Tree of Parzen Estimators (TPE).\n",
    "Полезные ссылки: \n",
    "\n",
    "Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms\n",
    "Hyperopt на GitHub\n",
    "Байесовский ниндзя (Хабр)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плюсы и минусы рассмотренных фреймворков и библиотек\n",
    "\n",
    "Название\tПлюсы \tМинусы\n",
    "GridSearchCV\t\n",
    "✔️ Простой в использовании, идеален для небольшой сетки гиперпараметров\n",
    "\n",
    "✔️ Встроенная кросс-валидация\n",
    "\n",
    "✔️ Включает построение итоговой модели на всей обучающей выборке \n",
    "\n",
    "⛔️ Перебирает просто все комбинации заданной сетки гиперпараметров \n",
    "\n",
    "⛔️  Требует много времени и вычислительных ресурсов\n",
    "\n",
    "RandomizedSearchCV\t✔️ Эффективнее и экономичнее gridsearchcv\n",
    "✔️ Можно задать количество рассматриваемых комбинаций\n",
    "\n",
    "⛔️ Просто выбирает рандомные комбинации гиперпараметров без учёта результатов прошлых итераций\n",
    "Hyperopt\t✔️ Быстрее и эффективнее, чем классические методы перебора (GSCV и RSCV)\n",
    "✔️ Учитывает результаты прошлых итераций — байесовский оптимизатор\n",
    "\n",
    "✔️ Можно отслеживать дополнительную информацию на каждом шаге с помощью класса Trials\n",
    "\n",
    "✔️ Возможность построения условного пространства поиска гиперпараметров и даже моделей\n",
    "\n",
    "⛔️ Старая документация, плохо с поддержкой и обновлением \n",
    "⛔️ Способен только минимизировать\n",
    "\n",
    "⛔️ Непростой синтаксис описания пространства гиперпараметров (особенно с использованием условных реализаций)\n",
    "\n",
    "Optuna\t✔️ Один из самых быстрых и эффективных\n",
    "✔️ Специально разработан для оптимизации гиперпараметров \n",
    "\n",
    "✔️ Простой в использовании\n",
    "\n",
    "✔️ Относительно новый фреймворк с хорошей документацией \n",
    "\n",
    "✔️ Учитывает результаты прошлых итераций — байесовский оптимизатор \n",
    "\n",
    "✔️ Встроенная визуализация результатов\n",
    "\n",
    "✔️ Возможность явно задавать максимизацию или минимизацию функции качества\n",
    "\n",
    "⛔️ Удаление «плохих» точек пространства из рассмотрения\n",
    "⛔️ Не стоит полностью полагаться: важно с умом определять пространство поиска, что может значительно сократить время расчётов."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
