{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, как мы уже неоднократно упоминали ранее, в машинном обучении есть два типа параметров.\n",
    "\n",
    "Внутренние (параметры модели)\n",
    "\n",
    "Подбираются во время обучения и определяют, как использовать входные данные для получения необходимого результата.\n",
    "\n",
    "Например, это веса (коэффициенты уравнения) в линейной/логистической регрессии.\n",
    "\n",
    "Внешние (параметры алгоритма)\n",
    "\n",
    "Их принято называть гиперпараметрами. Внешние параметры могут быть произвольно установлены перед началом обучения и контролируют внутреннюю работу обучающего алгоритма.\n",
    "\n",
    "Например, это параметр регуляризации в линейной/логистической регрессии.\n",
    "\n",
    "Гиперпараметры отвечают за сложность взаимосвязи между входными признаками и целевой переменной, поэтому сильно влияют на модель и качество прогнозирования.\n",
    "\n",
    "Продемонстрируем это на примере задачи регрессии с помощью двух графиков работы алгоритма случайного леса, построенного на основе 5, 100 деревьев (n_estimators = [5, 100]):\n",
    "\n",
    "\n",
    "\n",
    "Видим, что при 100 деревьях модель находит более сложную закономерность в данных и точность соответственно будет выше, чем при 5.\n",
    "\n",
    "Каждый алгоритм МО имеет набор гиперпараметров, которые определяют, как именно он строит модель на обучающей выборке. Например, в модуле ML-2 для повышения эффективности модели мы уже рассматривали подбор параметра регуляризации  для алгоритма линейной регрессии Ridge.\n",
    "\n",
    "Наилучшее значение метрики соответствует  (кстати, можно попробовать перебрать значения ).\n",
    "\n",
    "В данном случае мы просто воспользовались циклом for и перебрали некоторые заданные значения alpha, хотя, по всей видимости, не самые оптимальные. Поэтому подобранные эмпирическим путём значения гиперпараметров с большей вероятностью дадут низкую прогностическую эффективность.\n",
    "\n",
    "Также рассмотренный метод визуализации зависимости метрики от гиперпараметра позволяет выбрать только один внешний параметр, в данном случае — alpha. А что делать, если у нас не один, а несколько? \n",
    "\n",
    "Например, вспомним основные внешние параметры DecisionTreeClassifier:\n",
    "\n",
    "criterion — критерий информативности. Может быть равен 'gini' — критерий Джини — и 'entropy' — энтропия Шеннона.\n",
    "max_depth — максимальная глубина дерева. По умолчанию None, глубина дерева не ограничена.\n",
    "max_features — максимальное число признаков, по которым ищется лучшее разбиение в дереве. По умолчанию None, то есть обучение производится на всех признаках.\n",
    "min_samples_leaf — минимальное число объектов в листе. По умолчанию — 1.\n",
    "Мы, конечно, можем сделать кучу вложенных циклов. Однако, поскольку поиск оптимальных значений гиперпараметров является общераспространенной задачей МО, библиотека scikit-learn и другие предлагают методы, позволяющие её решить.\n",
    "\n",
    "Тщательный подбор гиперпараметров гарантирует, что модель покажет максимально возможную точность на обучающих данных, но это совершенно не означает хороший результат на тестовых или новых данных.\n",
    "\n",
    "Поиск оптимальных значений гиперпараметров модели является сложной задачей, обязательной почти для всех моделей и наборов данных. Однако важно понимать смысл гиперпараметров перед их подбором.\n",
    "\n",
    "Цели модуля\n",
    "\n",
    "Узнать, какие есть базовые способы оптимизации гиперпараметров (GridSearchCV, RandomSearchCV).\n",
    "Узнать, какие есть продвинутые способами оптимизации (Hyperopt, Optuna).\n",
    "Научиться их настраивать и обучать модели с их использованием — так, чтобы улучшать итоговую метрику.  \n",
    "Провести сравнение и понять преимущества и недостатки каждого из методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В базовой оптимизации, предоставляемой библиотекой sklearn, есть два основных метода — grid search и random search. С ними мы сейчас и познакомимся. Оба используются при решении реальных задач, поэтому важно разобраться, как они устроены. \n",
    "\n",
    "Наиболее часто используемый метод — это поиск по сетке (grid search), который по сути является попыткой перебрать все возможные комбинации заданных гиперпараметров. Мы указываем список значений для различных гиперпараметров, и, ориентируясь на нашу метрику, оцениваем эффективность модели для каждого их сочетания, чтобы получить оптимальную комбинацию значений.\n",
    "\n",
    "Допустим, мы хотим подобрать гиперпараметры min_samples_leaf и max_depth для алгоритма DecisionTreeClassifier. Зададим списки их значений:\n",
    "\n",
    "min_samples_leaf = [3, 5, 8, 9]\n",
    "max_depth = [4, 5, 6, 7, 8]\n",
    " \n",
    "\n",
    "Поскольку нам нужно перебрать четыре различных значения для min_samples_leaf и пять — для max_depth, то получается всего 4*5=20 комбинаций. Модель будет обучена 20 раз; столько же раз будет рассчитана метрика.\n",
    "\n",
    "Опасность переобучения и утечки данных\n",
    "\n",
    "Для того, чтобы выбрать оптимальные значения гиперпараметров, мы ориентируемся на выбранную метрику, рассчитанную на тестовой выборке. Мы делали это для подбора гиперпараметра регуляризации alpha, но является ли это надёжным подходом?\n",
    "\n",
    "Эту проблему мы уже обсуждали в модуле ML-5 «Валидация и оценка качества моделей».\n",
    "\n",
    "Давайте вспомним: мы перебираем множество значений гиперпараметров и выбираем ту комбинацию значений, которая даёт наилучшую точность на тестовых данных. Однако это совсем не означает, что на новых данных мы получим такой же результат. \n",
    "\n",
    "Поскольку мы использовали тестовый набор для настройки гиперпараметров, мы больше не можем использовать его для оценки качества модели. Теперь в этих целях нам необходим независимый набор данных, то есть набор, который не использовался для построения модели и настройки её гиперпараметров.\n",
    "\n",
    "Следовательно, надо разбить данные на три части: обучающую для построения модели, проверочную (валидационную) для выбора гиперпараметров модели, а также тестовую для оценки качества модели и выбранных гиперпараметров. \n",
    "\n",
    "\n",
    "\n",
    "Наличие всех трёх наборов данных критически важно для использования МО. Любой подбор гиперпараметров, сделанный на тестовых данных, «сливает» модели информацию, содержащуюся в них, и может привести к неправильной оценке качества модели. Такая проблема относится к категории утечки данных, которую мы уже тоже затрагивали в модуле по валидации.\n",
    "\n",
    "Рассмотренный метод разбиения данных на обучающий, проверочный и тестовый наборы является вполне рабочим и относительно широко используемым, но весьма чувствителен к равномерности разбиения данных. \n",
    "\n",
    "Для лучшей оценки обобщающей способности вместо одного разбиения данных на обучающий и проверочный наборы мы можем воспользоваться перекрёстной проверкой, то есть кросс-валидацией (cross validation). В таком случае качество модели оценивается для каждой комбинации гиперпараметров по всем разбиениям кросс-валидации. \n",
    "\n",
    "\n",
    "\n",
    "Пояснение к рисунку. Предположим, что у нас есть n комбинаций гиперпараметров. Берём первую комбинацию и обучаем на них первую модель с помощью кросс-валидации с 10 фолдами (cv=10), затем рассчитываем метрику как среднее по всем разбиениям. Так проделываем для каждой комбинации и выбираем ту, при которой наша метрика наилучшая. В итоге мы обучим n*cv моделей, но выберем один набор гиперпараметров, который и будет использоваться для обучения итоговой модели на всей обучающей выборке.\n",
    "\n",
    "GridSearchCV\n",
    "\n",
    "Поскольку поиск по сетке с кросс-валидацией является весьма распространённым методом настройки гиперпараметров, библиотека scikit-learn предлагает класс GridSearchCV, в котором осуществляется именно такой вариант.\n",
    "\n",
    "RandomizedSearchCV \n",
    "\n",
    "Несмотря на то, что поиск по сетке — мощный метод для нахождения оптимального набора гиперпараметров, оценка всех возможных комбинаций требует множество времени и вычислительных ресурсов, а также кросс-валидации для обучения моделей.\n",
    "\n",
    "Альтернативным подходом подбора различных комбинаций гиперпараметров в библиотеке scikit-learn является RandomizedSearchCV. \n",
    "\n",
    "Рандомизированный поиск работает почти так же, как решётчатый поиск, за исключением того, что перебираются не всевозможные комбинации параметров, а из них случайным образом выбираются  возможных вариантов комбинаций. Количество комбинаций параметров (), которые используются в случайном поиске, мы задаём самостоятельно, что позволяет управлять временем, затрачиваемым на оптимизацию.\n",
    "\n",
    "\n",
    "\n",
    "Источник\n",
    "\n",
    "На этой картинке изображено принципиальное различие двух методов: \n",
    "\n",
    "В GridSearchCV сетка задаётся вручную, перебираются различные значения гиперпараметров с каким-то шагом, в итоге получается что-то похожее на «красивую» сетку слева на картинке. Однако минимум функции (белое пятно) мы так и не обнаруживаем — а ведь он где-то рядом, возможно, просто между подобранными нами комбинациями.\n",
    "RandomizedSearchCV выбирает n (количество задаём сами) случайных точек/комбинаций из заданных нами последовательностей. Как следствие, мы можем перебирать не все возможные точки, а только часть из них, тем самым управляя скоростью работы перебора.\n",
    "Основные параметры RandomizedSearchCV аналогичны GridSearchCV, за исключением наименований некоторых параметров и наличия параметра n_iter:\n",
    "\n",
    "estimator — алгоритм, который будем оптимизировать;\n",
    "param_distributions — cловарь с именами параметров (str) в качестве ключей и списками параметров в качестве значений, которые нужно попробовать.\n",
    "\n",
    "В таком случае каждый словарь в списке перебирается отдельно и последовательно. Это позволяет выполнять поиск по любой последовательности настроек параметров.\n",
    "\n",
    "Например, если количество итераций (параметр n_iter) равно 2, то сначала будет дважды выбрана случайная комбинация параметров модели из словаря {'max_depth': [5, 8, 10], 'min_samples_leaf': [7, 8, 9]}, а после этого, опять же дважды, случайная комбинация из словаря {'n_estimators': [100, 200, 300], 'max_depth': [5, 8, 10]}.\n",
    "\n",
    "scoring — по умолчанию используется score-функция заданного алгоритма:\n",
    "для классификации — sklearn.metrics.accuracy_score;\n",
    "\n",
    "для регрессии — sklearn.metrics.r2_score.\n",
    "\n",
    "Возможно выбрать любую другую в зависимости от условий задачи. Различные варианты смотрите здесь.\n",
    "\n",
    "cv — количество фолдов в кросс-валидации, по умолчанию используется 5.\n",
    "n_jobs — количество ядер для распараллеливания расчёта. -1 использует все существующие ядра.\n",
    "n_iter — количество комбинаций на расчёт. От этого параметра напрямую зависит время оптимизации и качество модели.\n",
    "\n",
    "Рекомендации по настройке гиперпараметров ансамблей над решающими деревьями\n",
    "\n",
    "Алгоритм случайного леса (RandomForest)\n",
    "\n",
    "n_estimators — число итераций (количество деревьев). Частично работает правило «чем больше, тем лучше», но иногда это не имеет особого смысла и сильно увеличивает затраты, поэтому стоит пробовать обучать сотни деревьев [100,200, 300, 400]. Если нет изменений, то оставить минимальное — 100.\n",
    "max_depth — максимальная глубина дерева. В случайном лесе строятся «сильные» деревья, каждое из которых даёт полноценный прогноз, поэтому глубина деревьем может быть достаточно большой. Стоит следить за переобучением.\n",
    "max_features — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения;\n",
    "max_samples — доля выборки, которая будет использоваться для обучения каждого алгоритма — дерева.\n",
    "Примечание. Так как алгоритм градиентного бустинга мы ещё не проходили, вы можете вернуться в данный раздел, когда изучите модуль ML-8.\n",
    "\n",
    "Алгоритм градиентного бустинга (GradientBoosting)\n",
    "\n",
    "n_estimators — число итераций (количество деревьев) : хотя ошибка на обучении монотонно стремится к нулю, ошибка на контроле, как правило, начинает увеличиваться после определенной итерации. Оптимальное число итераций можно выбирать, например, по отложенной выборке или с помощью кросс-валидации.\n",
    "learning_rate — темп обучения (0;1]:\n",
    "На практике оказывается, что градиентный бустинг очень быстро строит композицию, ошибка которой на обучении выходит на асимптоту (достигает предела), после чего начинает настраиваться на шум и переобучаться. Параметр learning_rate контролирует, насколько сильно каждое дерево будет пытаться исправить ошибки предыдущих деревьев. Более высокая скорость обучения означает, что каждое дерево может внести более сильные корректировки. Как правило, чем меньше темп обучения, тем лучше качество итоговой композиции.\n",
    "\n",
    "max_depth — максимальная глубина дерева. Используется для борьбы с переобучением. Рекомендуется устанавливать не более 5.\n",
    "max_features — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения.\n",
    "subsample — доля выборки, которая будет использоваться для обучения каждого алгоритма. Это ещё один способ улучшения качества градиентного бустинга. Таким образом вносится рандомизация в процесс обучения базовых алгоритмов, что снижает уровень шума в обучении, а также повышает эффективность вычислений. \n",
    "Рекомендация. Берите подвыборки, размер которых вдвое меньше исходной выборки.\n",
    "\n",
    "\n",
    "\n",
    "Главное отличие техник Bagging и Boosting состоит в параллельном и последовательном построении деревьев соответственно.\n",
    "\n",
    "Основные параметры градиентного бустинга деревьев — это количество деревьев (n_estimators) и скорость обучения (learning_rate), контролирующие степень вклада каждого дерева в устранение ошибок предыдущих деревьев. Эти два параметра тесно взаимосвязаны, поскольку более низкое значение learning_rate означает, что для построения модели аналогичной сложности необходимо большее количество деревьев.\n",
    "\n",
    "В отличие от случайного леса, в котором более высокое значение n_estimators всегда дает лучшее качество, увеличение значения n_estimators в градиентном бустинге даёт более сложную модель, что может привести к переобучению. При всём этом случайный лес, в отличие от градиентного бустинга, использует глубокие деревья, способные сформировать полноценный прогноз. \n",
    "\n",
    "Общепринятая практика для бустинга — подгонять n_estimators в зависимости от бюджета времени и памяти, а затем подбирать различные значения learning_rate."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
