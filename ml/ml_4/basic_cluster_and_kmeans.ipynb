{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?\n",
    "\n",
    "Представьте, что вы работаете дата-сайентистом и получаете задачу по маркетинговому исследованию клиентов. Вам необходимо выделить группы покупателей по степени интереса к продукту и по сумме, которую они тратят.\n",
    "\n",
    "Как решить данную задачу?\n",
    "\n",
    "Обучение с учителем здесь не подходит, так как у нас нет правильных ответов о степени заинтересованности покупателей в продукте.\n",
    "\n",
    "Однако не спешите расстраиваться — на помощь придёт обучение без учителя, а именно кластеризация.\n",
    "\n",
    "Мы уже рассматривали суть кластеризации в модуле ML-1.\n",
    "\n",
    "img\n",
    "\n",
    "Кластеризация позволяет разбить объекты на группы, которые называются кластерами.\n",
    "\n",
    "Например, на картинке ниже изображены разные кластеры еды и напитков:\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "→ Похожие объекты оказываются внутри одного кластера. Если же объекты разные, то они должны оказаться в разных кластерах.\n",
    "\n",
    "Также у каждого кластера есть центроид.\n",
    "\n",
    "Центроид — это центр масс кластера, или среднее значение координат объектов кластера.\n",
    "\n",
    "На рисунке ниже изображено три кластера, крестик в каждом из них — это центроид:\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "Как найти этот центроид?\n",
    "\n",
    "Допустим, у нас есть маленький кластер, состоящий из четырёх точек. Каждая точка описывается только одним свойством — , рост человека:\n",
    "\n",
    ", рост\n",
    "Человек № 1\t180\n",
    "Человек № 2\t170\n",
    "Человек № 3\t181\n",
    "Человек № 4\t160\n",
    "Тогда для нахождения центроида мы берём все значения по оси x и считаем среднее:\n",
    "\n",
    "ц\n",
    "е\n",
    "н\n",
    "т\n",
    "р\n",
    "о\n",
    "и\n",
    "д\n",
    "к\n",
    "л\n",
    "а\n",
    "с\n",
    "т\n",
    "е\n",
    "р\n",
    "а\n",
    "Что делать, если данные описываются двумя свойствами, например, рост () и вес ()?\n",
    "\n",
    "Тогда у этих точек есть - и -координаты:\n",
    "\n",
    ", рост\t, вес\n",
    "Человек № 1\t180\t70\n",
    "Человек № 2\t170\t60\n",
    "Человек № 3\t181\t65\n",
    "Человек № 4\t160\t45\n",
    "Для нахождения координат центроида мы последовательно находим:\n",
    "\n",
    "Координату : \n",
    "ц\n",
    "е\n",
    "н\n",
    "т\n",
    "р\n",
    "о\n",
    "и\n",
    "д\n",
    ".\n",
    "Координату : \n",
    "ц\n",
    "е\n",
    "н\n",
    "т\n",
    "р\n",
    "о\n",
    "и\n",
    "д\n",
    ".\n",
    "Таким образом, координаты центроида — (172, 60).\n",
    "\n",
    "Если объект описывается бόльшим количеством признаков (например, рост (), вес (), объём талии () и т. д.), то для нахождения координат центроида мы последовательно, по каждому признаку (координате), ищем среднее значение.\n",
    "\n",
    "Алгоритм k-means\n",
    "\n",
    "Рассмотрим один из наиболее популярных методов кластеризации — k-means.\n",
    "\n",
    "Данный алгоритм был разработан ещё в 1950-х, но благодаря скорости своей работы он до сих пор остаётся востребованным.\n",
    "\n",
    "Идея алгоритма состоит в том, что он разбивает множество элементов векторного пространства на заранее заданное пользователем число кластеров, а далее стремится минимизировать суммарное квадратичное отклонение объектов внутри кластера до центроида кластера.\n",
    "\n",
    "Математически это выглядит следующим образом: \n",
    "\n",
    "Мы итерируемся по каждому кластеру и для всех векторов  внутри кластера  подсчитываем центроиды (). Далее рассчитываем разницу между каждым вектором  кластера  и центроидом кластера . Необходимо, чтобы это значение, возведённое в квадрат (), было минимальным для каждого кластера.\n",
    "\n",
    "А сейчас переведём сложные математические термины на человеческий язык.\n",
    "\n",
    "Рассмотрим работу данного алгоритма на примере. Допустим, у нас есть данные с разными значениями свойства . Эти данные необходимо разделить на кластеры. Нанесём значения свойства  на ось X:\n",
    "\n",
    "img\n",
    "Для этих данных нам нужно провести анализ и выделить три кластера. Вы с большой вероятностью скажете, что данные можно разделить на кластеры (жёлтый, розовый и зелёный) следующим образом:\n",
    "\n",
    "img\n",
    "Но как реализовать это в алгоритме? Алгоритм k-means состоит из девяти шагов. Давайте подробно рассмотрим каждый из них:\n",
    "\n",
    "1\n",
    "Решаем, на сколько кластеров хотим разделить данные.\n",
    "\n",
    "В данном случае у нас будет три кластера. Значит, у алгоритма k-means .\n",
    "\n",
    "img\n",
    "2\n",
    "Чтобы сформировать кластеры, случайным образом выбираем три объекта из датасета. Эти три объекта будут представлять три разных кластера (жёлтый, розовый и зелёный). Так как в этих кластерах находится по одному объекту, то эти объекты будут считаться исходными центроидами кластеров:\n",
    "\n",
    "img\n",
    "3\n",
    "Распределим оставшиеся объекты датасета по трём кластерам.\n",
    "\n",
    "Считается, что объект принадлежит к тому кластеру, к центроиду которого он находится ближе всего.\n",
    "\n",
    "Возьмём первый объект датасета и рассчитаем расстояние (L1, L2 и L3) от этого объекта до центроида каждого кластера:\n",
    "\n",
    "img\n",
    "Найдём, к какому центроиду данный объект находится ближе всего. L1 имеет наименьшее значение — значит, объект располагается ближе всего к центроиду жёлтого кластера и будет отнесён к нему:\n",
    "\n",
    "img\n",
    "После этого такую же процедуру мы проводим для остальных объектов датасета. В итоге получаем следующее распределение данных:\n",
    "\n",
    "img\n",
    "Два объекта оказались ближе всего к розовому кластеру, три объекта — к зелёному.\n",
    "\n",
    "4\n",
    "Теперь в каждом из кластеров больше одного объекта, и центр этих кластеров тоже изменился. Поэтому рассчитаем новые центроиды и для удобства выделим их на рисунке вертикальной линией:\n",
    "\n",
    "img\n",
    "5\n",
    "После этого для каждого объекта в выборке повторяем шаг 3, т. е. для каждого объекта датасета рассчитываем расстояние до центроидов:\n",
    "\n",
    "img\n",
    "Так как у нас новые кластеры, центроиды могли сильно измениться. Поэтому при подсчёте расстояний ближайшим к объекту может оказаться уже другой центроид. Значит, этот объект будет принадлежать к другому кластеру.\n",
    "\n",
    "В нашем случае центроиды изменились несильно, и все объекты остались в своих кластерах.\n",
    "\n",
    "6\n",
    "Шаг 5 повторяется до тех пор, пока объекты датасета не перестанут менять кластеры, к которым они относятся. Как только объекты перестают это делать, алгоритм завершается и мы переходим к шагу 7.\n",
    "\n",
    "7\n",
    "Далее для каждого кластера подсчитаем средний квадрат расстояния от объектов до центров их кластеров.\n",
    "\n",
    "Находим суммарное отклонение:\n",
    "\n",
    "img\n",
    "8\n",
    "Далее мы несколько раз заново запускаем алгоритм кластеризации, начиная с шага 2.\n",
    "\n",
    "Зачем это нужно?\n",
    "\n",
    "В шаге 1 мы выбирали первые объекты кластера случайным образом, но так можно выбрать не разные объекты, а те, что находятся рядом. В таком случае кластеризация получится некачественной (шесть оставшихся объектов будут принадлежать к зелёному кластеру), как на рисунке ниже:\n",
    "\n",
    "img\n",
    "Чтобы такого не происходило, мы повторяем весь алгоритм несколько раз, начиная с шага 2. В sklearn по умолчанию проводится десять итераций.\n",
    "\n",
    "9\n",
    "Среди получившихся кластеров нам необходимо найти наилучший вариант кластеризации.\n",
    "\n",
    "Лучшей будет признана кластеризация с минимальным значением среднеквадратичного отклонения, которое рассчитывали на шаге 7.\n",
    "\n",
    "Очевидно, что если все объекты будут в одном кластере, это будет худший сценарий с максимальным среднеквадратичным отклонением:\n",
    "\n",
    "img\n",
    "Если каждый объект будет принадлежать собственному кластеру, отклонение будет нулевым, так как один объект будет являться и объектом кластера, и его центром масс, а значит расстояние между объектом кластера и центроидом кластера равно нулю. Такое разбиение будет считаться переобучением, так как мы слишком подстраиваемся под данные:\n",
    "\n",
    "img\n",
    "Только что мы рассмотрели, как работает алгоритм для одномерного случая (если есть только один признак, описывающий объект). Ниже вы можете увидеть, как работает алгоритм для двухмерного случая (когда объект описывается двумя признаками).\n",
    "\n",
    "img\n",
    "\n",
    "Если объект описывается тремя и более признаками, поиск кластеров идёт в -мерном пространстве признаков. Однако такую работу алгоритма довольно сложно визуализировать.\n",
    "\n",
    "Рассмотренный нами алгоритм был основан на центроидах: мы находили центры кластеров и присваивали объекты к ближайшему центроиду кластера.\n",
    "\n",
    "На самом деле центры кластера инициализируют разными способами. В зависимости от этого выделяется несколько вариаций алгоритма k-means:\n",
    "\n",
    "Название\tПРинцип работы\tПодробности\n",
    "k-means\t\n",
    "Находит центроиды кластера как среднее значение координат.\n",
    "\n",
    "Документация\n",
    "\n",
    "(init='random')\n",
    "\n",
    "K-MEANS++\t\n",
    "В классическом алгоритме k-means центроиды выбираются случайно, но это может приводить к тому, что два объекта, которые находятся близко друг к другу, будут центроидами двух разных кластеров — это будет приводить к долгой работе алгоритма.\n",
    "\n",
    "Алгоритм k-means++ чуть «хитрее» и выбирает центроиды кластеров не совсем случайно.\n",
    "\n",
    "Документация\n",
    "\n",
    "(init='k-means++'; по умолчанию в sklearn при запуске k-means используется алгоритм k-means++)\n",
    "\n",
    "k-medians\t\n",
    "На этапе поиска центроидов кластера находит не среднее значение координат, а медиану.\n",
    "\n",
    "Документация\n",
    "\n",
    "k-medoids\t\n",
    "Работает так же, как k-medians, но медианой кластера будет не какая-то точка в кластере, а объект, который находится ближе всего к этим координатам медианы кластера.\n",
    "\n",
    "Документация\n",
    "fuzzy c-means\t\n",
    "Данный алгоритм разрешает нечётко присваивать кластеры. Каждый объект может принадлежать к разным кластерам с разной вероятностью.\n",
    "\n",
    "Документация\n",
    "Теперь мы знаем, как работает алгоритм k-means, но не хотелось бы реализовывать его с нуля. Для того чтобы запустить алгоритм кластеризации k-means, нам нужна библиотека sklearn и модуль KMeans.\n",
    "\n",
    "Что необходимо для запуска?\n",
    "\n",
    "Обязательно задать количество кластеров, на которые необходимо разделить данные.\n",
    "Данные, т. е. параметры объектов (), которые мы будем передавать в виде матрицы наблюдений X.\n",
    "После этого можно запустить алгоритм и для каждого объекта в данных получить метку, к какому кластеру этот объект относится:\n",
    "\n",
    "# импортируем нужный модуль k-means-кластеризации\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# инициализируем алгоритм, при желании задаём разные параметры для алгоритма\n",
    "k_means = KMeans(n_clusters=2, init='k-means++', n_init=10, random_state=42)\n",
    "X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "# обучаем модель на данных, передав матрицу наблюдений X\n",
    "k_means.fit(X)\n",
    "# получаем результаты кластеризации (список меток, к какому кластеру относится каждый объект из X)\n",
    "labels = k_means.labels_\n",
    "Таким образом, мы обучили модель кластеризации. Если нужно определить, к какому из существующих кластеров будут отнесены новые данные из df2, то мы просто воспользуемся методом predict:\n",
    "\n",
    "X_new = df2[[\"x1\", \"x2\", \"x3\"]]\n",
    "k_means.predict(X_new)\n",
    "Чтобы запустить алгоритм, необходимо задать параметры кластеризации:\n",
    "\n",
    "n_clusters — количество кластеров. По умолчанию — 8.\n",
    "init — способ инициализации центроидов. Есть две опции: random (выбирает центроиды случайным образом) и k-means++ (более «хитрый» алгоритм, который позволяет модели быстрее сходиться). По умолчанию используется k-means++.\n",
    "n_init — количество случайных инициализаций алгоритма k-means. В конце будут выбраны те результаты, которые имеют наилучшие значения критерия k-means. По умолчанию n_init = 10.\n",
    "max_iter — максимальное количество итераций алгоритма k-means при одном запуске. По умолчанию — 300.\n",
    "random_state — параметр, который определяет генерацию случайных чисел для инициализации центроида. Чтобы детерминировать случайность, нужно задать какое-нибудь число.\n",
    "Теперь попробуем применить полученные знания на практике.\n",
    "\n",
    "У нас есть данные по покемонам. Для каждого покемона известны его сила атаки, уровень защиты, скорость бега и ещё пара параметров. Попробуем найти кластеры покемонов, основываясь на силе атаки и уровне защиты.\n",
    "\n",
    "\n",
    "Скачать данные\n",
    "Скачать ноутбук\n",
    "# импортируем библиотеку pandas для работы с датафреймами\n",
    "import pandas as pd\n",
    "# импортируем seaborn для визуализации\n",
    "import seaborn as sns\n",
    "# импортируем sklearn для кластеризации\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# загружаем данные\n",
    "df = pd.read_csv('pokemon.csv')\n",
    "# датасет содержит название покемона, уровень его защиты, силу атаки и скорость\n",
    "df.head()\n",
    "img\n",
    "# попробуем кластеризовать покемонов по их силе атаки и уровню защиты\n",
    "# для этого сохраним в матрицу X два интересующих нас признака: атаку и защиту\n",
    "X = df[['Attack', 'Defense']]\n",
    "\n",
    "# визуализируем\n",
    "sns.scatterplot(x=df.Attack, y=df.Defense)\n",
    "img\n",
    "Из получившегося графика непонятно, сколько кластеров должно быть и как их выбрать. Попробуем разделить данные на три кластера.\n",
    "\n",
    "Инициализируем алгоритм k-means. При инициализации зададим параметры моделирования:\n",
    "\n",
    "n_clusters — количество кластеров;\n",
    "init — стратегия кластеризации;\n",
    "n_init — количество запусков алгоритма k-means;\n",
    "random_state — чтобы результаты воспроизводились от запуска к запуску.\n",
    "# инициализируем алгоритм k-means с количеством кластеров 3\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', n_init=10, random_state=42)\n",
    "\n",
    "# запустим обучение модели\n",
    "kmeans.fit(X)\n",
    "\n",
    "# предскажем, к какому кластеру принадлежат покемоны \n",
    "predictions = kmeans.predict(X)\n",
    "# если мы хотим получить метки класса для тех же данных, на которых обучили модель, можно запросить labels\n",
    "predictions = kmeans.labels_\n",
    "\n",
    "# сохраним предсказания в датафрейм\n",
    "df['Clusters_k3'] = predictions\n",
    "\n",
    "#визуализируем результаты. Параметр c принимает вектор с номерами классов для группировки объектов по цветам \n",
    "sns.scatterplot(x=df.Attack, y=df.Defense, c=predictions)\n",
    "img\n",
    "В данном случае видно, что данные хорошо делятся на три кластера, а также есть одна точка-выброс. \n",
    "\n",
    "Попробуем увеличить количество кластеров до четырёх, чтобы вынести выброс в отдельный кластер:\n",
    "\n",
    "# инициализируем алгоритм k-means с количеством кластеров 4\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', n_init=10, random_state=42)\n",
    "\n",
    "# запустим обучение модели\n",
    "kmeans.fit(X)\n",
    "\n",
    "# предскажем, к какому кластеру принадлежат покемоны \n",
    "predictions = kmeans.predict(X)\n",
    "# если мы хотим получить метки класса для тех же данных, на которых обучили модель, то можно просто попросить labels\n",
    "predictions = kmeans.labels_\n",
    "\n",
    "# сохраним предсказания в датафрейм\n",
    "df['Clusters_k4'] = predictions\n",
    "\n",
    "#визуализируем результаты, параметр c принимает вектор с номерами классов для группировки объектов по цветам \n",
    "sns.scatterplot(x=df.Attack, y=df.Defense, c=df.Clusters_k4)\n",
    "img\n",
    "Как видим, «отделить» выброс от других данных не получается: k-means не умеет обрабатывать выбросы.\n",
    "\n",
    "В данном случае мы проводили кластеризацию по двум признакам. Мы сделали это для того, чтобы можно было визуализировать результаты. Для кластеризации можно использовать и более двух признаков, однако в таком случае кластеризация будет проходить в -мерном пространстве (для трёх признаков пространство будет трёхмерным), и визуализировать результаты будет непросто.\n",
    "\n",
    "В трёхмерном и другом -мерном случае кластеризация запускается следующим образом:\n",
    "\n",
    "# добавляем третий признак — скорость покемона, алгоритм такой же\n",
    "X = df[['Attack', 'Defense', 'Speed']]\n",
    " \n",
    "# инициализируем алгоритм k-means с количеством кластеров 3\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', n_init=10, random_state=42)\n",
    " \n",
    "# запускаем обучение модели\n",
    "kmeans.fit(X)\n",
    " \n",
    "# предсказываем, к какому кластеру принадлежат покемоны \n",
    "predictions = kmeans.predict(X)\n",
    "# если мы хотим получить метки класса для тех же данных, на которых обучили модель, можно запросить labels\n",
    "predictions = kmeans.labels_\n",
    "Методы визуализации результатов 3D-кластеризации мы рассмотрим чуть позже.\n",
    "\n",
    "Недостатки алгоритма k-means\n",
    "\n",
    "Необходимо заранее знать, на сколько кластеров мы хотим разделить данные. В учебных примерах известно, каким должно быть k, и определить это значение довольно легко. В реальности данные сложнее и трудно заранее предугадать, сколько кластеров мы хотим получить.\n",
    "\n",
    "Очевидно, что для объектов, которые в равной степени принадлежат к разным кластерам, алгоритм k-means будет отрабатывать плохо.\n",
    "\n",
    "Алгоритм чувствителен к выбросам в данных, так как выбросы сильно искажают местонахождение центроида кластера.\n",
    "\n",
    "Например, на картинке ниже зелёная точка справа — явный выброс. Но получилось так, что этот выброс находится ближе всего к зелёному кластеру, поэтому выброс был отнесён к нему. При подсчёте центроида для зелёного кластера появится искажение, так как выброс сильно на это повлияет:\n",
    "\n",
    "img\n",
    "Плохо работает на данных, которые образуют удлинённые кластеры, а также на кластерах неправильной формы.\n",
    "\n",
    "Например, если данные распределены, как на левом и среднем рисунках ниже, алгоритм k-means будет проводить кластеризацию некорректно и выделять два довольно странных кластера (синий и оранжевый). На правом рисунке изображены кластеры удлинённой формы, и для них k-means также отрабатывает плохо. Так происходит потому, что алгоритм ищет ближайших соседей и поэтому выделяет зелёным две нижних части двух разных кластеров, считая их ближайшими соседями.\n",
    "\n",
    "img\n",
    "Так как в самом начале работы алгоритма центроиды определяются случайным образом, результат сильно зависит от того, какие начальные объекты будут определены как центры кластеров.\n",
    "\n",
    "Определение оптимального k для алгоритма k-means\n",
    "\n",
    "Рассмотрим, как побороть один из существенных недостатков алгоритма, а именно — как подобрать оптимальное количество кластеров.\n",
    "\n",
    "→ Для этого можно использовать несколько способов: метод локтя (elbow plot), статистику разрыва (Gap Statistic Method), коэффициент силуэта (Average Silhouette Method). Мы рассмотрим метод локтя и коэффициент силуэта.\n",
    "\n",
    "Начнём с метода локтя.\n",
    "\n",
    "Данный метод позволяет найти такое оптимальное число кластеров, чтобы добавление ещё одного кластера не приводило к лучшему моделированию данных.\n",
    "\n",
    "Идея состоит в том, что в самом начале при добавлении новых кластеров качество моделирования улучшается. Эта область называется недообученной (underfitting).\n",
    "\n",
    "Дальнейшее добавление новых кластеров существенно не улучшает качество моделирования, а значит стоит прекратить их добавление. Данная область называется переобученной (overfitting).\n",
    "\n",
    "Чтобы определить оптимальное количество кластеров, используя метод локтя, необходимо нарисовать график, на котором по оси x будет отложено количество кластеров, а по оси y — инерция.\n",
    "\n",
    "Инерция — это сумма квадратов расстояний объектов датасета до центра масс ближайшего к ним кластера.\n",
    "\n",
    "img\n",
    "\n",
    "Когда инерция быстро снижается, область считается недообученной, а далее, после «перегиба», идёт очень медленное снижение инерции, и область считается переобученной.\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "На графике видно, что линия напоминает локоть — отсюда и название метода. Оптимальное число кластеров находится как раз на «локтевом сгибе». \n",
    "\n",
    "Таким образом, нам необходимо построить график и найти тот самый перегиб с оптимальным количеством кластеров. В данном случае оптимальное количество кластеров равно 4.\n",
    "\n",
    "Теперь реализуем это в виде кода. Нам нужно посчитать значение инерции для кластеризаций с разным количеством кластеров. Для этого напишем функцию get_inertia, которая будет принимать данные и количество кластеров и возвращать значение инерции:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# функция, которая принимает количество кластеров для k-means и матрицу с признаками объектов и возвращает инерцию \n",
    "def get_inertia(cluster_num, X):\n",
    "# инициализируем алгоритм кластеризации\n",
    "    k_means =  KMeans(n_clusters=cluster_num, random_state=42)\n",
    "# запускаем алгоритм k-means\n",
    "    k_means.fit(X)\n",
    "# находим значение инерции\n",
    "    inertia = k_means.inertia_\n",
    "# возвращаем значение инерции\n",
    "    return inertia\n",
    "\n",
    "# создаём пустой список для значений инерции\n",
    "inertia = []\n",
    "# итерируемся по разным размерам кластеров (от 1 до 9) и сохраняем значение инерции для каждого кластера\n",
    "for cluster_num in range(1, 10):\n",
    "# сохраняем значения\n",
    "    inertia.append(get_inertia(cluster_num, X))\n",
    "\n",
    "# визуализируем, как менялась инерция в зависимости от количества кластеров\n",
    "# задаём названия осям x и y\n",
    "plt.xlabel(\"cluster\", fontsize=12)\n",
    "plt.ylabel(\"inertia\", fontsize=12)\n",
    "# рисуем изменение инерции\n",
    "plt.plot([i for i in range(1, 10)], inertia, 'xb-')\n",
    "img\n",
    "Как можно заметить из графика, на сгибе k=3. Значит, оптимальное количество кластеров, подобранное с помощью алгоритма локтя, равняется трём. Значения k от 1 до 2 — недообученная область, а после значения 3 идёт переобучение.\n",
    "\n",
    "→ Таким образом, метод локтя — это довольно простой метод, основанный на учёте евклидова расстояния между объектами кластера и центроидами.\n",
    "\n",
    "Однако изгиб на графике также может быть представлен нечётко:\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "Как быть в таком случае? Какое оптимальное количество кластеров выбрать?\n",
    "\n",
    "Если вдруг в ходе работы вы встречаете график, на котором невозможно найти «локоть», на помощь придёт коэффициент силуэта.\n",
    "\n",
    "График силуэта, в отличие от графика локтя, имеет пиковый характер, поэтому его проще визуализировать и анализировать.\n",
    "\n",
    "На графике ниже по оси x отложено количество кластеров, а по оси y — значение коэффициента силуэта. Можно отчётливо увидеть, что пик графика приходится на количество кластеров, равное 3:\n",
    "\n",
    "img\n",
    "Коэффициент силуэта показывает, насколько объект похож на объекты кластера, в котором он находится, по сравнению с объектами из других кластеров.\n",
    "\n",
    "Силуэт варьируется от -1 до +1: чем выше значение, тем больше объекты похожи на объекты своего кластера и меньше похожи на объекты соседних кластеров.\n",
    "\n",
    "Если силуэт равен 1, это означает, что кластеры хорошо разделены между собой и имеют высокую плотность внутри себя, например, такая кластеризация, где данные чётко разделены на три группы:\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "Рассмотрим, как рассчитывается коэффициент силуэта, если у нас есть три разных кластера (красный, зелёный и серый):\n",
    "\n",
    "img\n",
    "Возьмём красный кластер. Для объекта из красного кластера рассчитаем расстояние до каждого объекта в этом кластере (пусть это будет ). Далее для красного кластера найдём ближайший кластер. Посчитаем расстояние от того же объекта из красного кластера  до каждого объекта зелёного кластера (примем это значение за ).\n",
    "\n",
    "Для каждой точки датасета рассчитывается значение силуэта:\n",
    "\n",
    "Далее рассчитывается среднее значение силуэта для всего датасета.\n",
    "\n",
    "Посчитаем силуэт, используя sklearn:\n",
    "\n",
    "# импортируем метрику силуэта\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# напишем функцию, как и при подсчете метода локтя\n",
    "def get_silhouette(cluster_num, X):\n",
    "    k_means =  KMeans(n_clusters=cluster_num, init='k-means++', n_init=10, random_state=42)\n",
    "    k_means.fit(X)\n",
    "# подсчитаем метрику силуэта, передав данные и то, к каким кластерам относятся объекты\n",
    "    silhouette = silhouette_score(X, k_means.predict(X))\n",
    "    return silhouette\n",
    "\n",
    "# создадим пустой словарь, ключами будут инерция и количество кластеров\n",
    "silhouette_res = {\"silhouette\": [], \"cluster\": []}\n",
    "\n",
    "# выберем нужные данные \n",
    "X = df[['Attack', 'Defense']]\n",
    "\n",
    "for cluster_num in range(2, 10):\n",
    "    silhouette_res[\"silhouette\"].append(get_silhouette(cluster_num, X))\n",
    "    silhouette_res[\"cluster\"].append(cluster_num)\n",
    "    \n",
    "# сохраним в датафрейм значение силуэта и количество кластеров\n",
    "silhouette_df = pd.DataFrame(silhouette_res)\n",
    "\n",
    "# установим стиль для визуализиции\n",
    "sns.set_style(\"darkgrid\")\n",
    "# визуализируем зависимость значения инерции от количества кластеров\n",
    "sns.lineplot(data=silhouette_df, x=\"cluster\", y=\"silhouette\", marker= \"o\")\n",
    "img\n",
    "На графике для метода силуэта отчётливо виден пик с наибольшим значением коэффициента силуэта. Значит, оптимальное количество кластеров равно 3.\n",
    "\n",
    "Если вам нужно найти оптимальное количество кластеров для датасета, наиболее наглядным графиком будет график коэффициента силуэта, поэтому можно сразу воспользоваться им. Но стоит помнить, что для построения данного графика нужно минимум два кластера, так как мы сравниваем объекты одного кластера с другим, наиболее близким кластером.\n",
    "\n",
    "Задание 2.1\n",
    "1/1 point (graded)\n",
    "Что такое центроид кластера?\n",
    "Среднее значение координат всех объектов датасета.\n",
    "Среднее значение координат объектов кластера.\n",
    "Среднее значение координат всех объектов, находящихся в заданном радиусе друг от друга.\n",
    "Минимальные значения координат всех объектов кластера\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.2\n",
    "1/1 point (graded)\n",
    "Что пытается минимизировать алгоритм k-means?\n",
    "Суммарное квадратичное отклонение объектов внутри кластера до центроида кластера\n",
    "Суммарное квадратичное отклонение всех объектов датасета до центроида датасета\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.3\n",
    "1/1 point (graded)\n",
    "Если в результате работы алгоритма кластеризации k-means каждый объект принадлежит отдельному кластеру, такая модель будет считаться...\n",
    "недообученной\n",
    "переобученной\n",
    "оптимально обученной\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.4\n",
    "1/1 point (graded)\n",
    "Какие метрики и индексы можно использовать для того, чтобы найти оптимальное количество кластеров?\n",
    "Отметьте все подходящие варианты ответов.\n",
    "\n",
    "A Метод локтя\n",
    "B Индекс Рэнда\n",
    "C V-мера\n",
    "D Коэффициент силуэта\n",
    "верно\n",
    "Ответ\n",
    "Верно:\n",
    "A Верно. Метод локтя позволяет найти оптимальное количество кластеров на сгибе.\n",
    "D Верно.\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.5\n",
    "1/1 point (graded)\n",
    "Вы проводите кластеризацию k-means и хотите найти оптимальное количество кластеров. Для этого вы воспользовались методом локтя и нарисовали график зависимости инерции от количества кластеров:\n",
    "\n",
    "img\n",
    "\n",
    "Каким будет оптимальное количество кластеров?\n",
    "\n",
    "5\n",
    "  верно \n",
    " \n",
    "Hint\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.6\n",
    "1/1 point (graded)\n",
    "На каких данных алгоритм k-means будет отрабатывать плохо?\n",
    "На данных удлинённой формы\n",
    "На данных с большим количеством выбросов\n",
    "На данных произвольной формы\n",
    "На данных, представляющих собой две окружности, вписанные друг в друга.\n",
    "На всех перечисленных разновидностях данных\n",
    "верно\n",
    "Show answer\n",
    "Отправить\n",
    "Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.\n",
    "Задание 2.7\n",
    "1/1 point (graded)\n",
    "Вам как специалисту по анализу данных поступили показания с прибора, измеряющего количество нитратов и пестицидов в разных фруктах и овощах.\n",
    "\n",
    "Значения количества пестицидов и нитратов записаны в столбцы с названиями x1 и x2.\n",
    "\n",
    "Основываясь на этих двух свойствах, кластеризуйте данные и, используя коэффициент силуэта, найдите оптимальное количество кластеров."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
